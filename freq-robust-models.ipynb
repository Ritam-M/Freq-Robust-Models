{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchattacks","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:04:08.317714Z","iopub.execute_input":"2021-10-23T12:04:08.318095Z","iopub.status.idle":"2021-10-23T12:04:20.472338Z","shell.execute_reply.started":"2021-10-23T12:04:08.318015Z","shell.execute_reply":"2021-10-23T12:04:20.470980Z"},"jupyter":{"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom scipy.fft import dct, idct\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nimport torchvision.utils\nfrom torchvision import models\nimport torchvision.datasets as dsets\nimport torchvision.transforms as transforms\n\nimport torchattacks\nfrom torchattacks import PGD, FGSM, CW\n\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:04:53.341529Z","iopub.execute_input":"2021-10-23T12:04:53.342463Z","iopub.status.idle":"2021-10-23T12:04:56.162581Z","shell.execute_reply.started":"2021-10-23T12:04:53.342368Z","shell.execute_reply":"2021-10-23T12:04:56.161481Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"mnist_train = dsets.MNIST(root='./data/',\n                          train=True,\n                          transform=transforms.ToTensor(),\n                          download=True)\n\nmnist_test = dsets.MNIST(root='./data/',\n                         train=False,\n                         transform=transforms.ToTensor(),\n                         download=True)\nbatch_size = 128\n\ntrain_loader  = torch.utils.data.DataLoader(dataset=mnist_train,\n                                           batch_size=batch_size,\n                                           shuffle=False)\n\ntest_loader = torch.utils.data.DataLoader(dataset=mnist_test,\n                                         batch_size=batch_size,\n                                         shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:04:56.766315Z","iopub.execute_input":"2021-10-23T12:04:56.766604Z","iopub.status.idle":"2021-10-23T12:04:58.634601Z","shell.execute_reply.started":"2021-10-23T12:04:56.766576Z","shell.execute_reply":"2021-10-23T12:04:58.633326Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"model = models.resnet18()\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nmodel.fc = torch.nn.Linear(512, 10)\nmodel = model.cuda()\n\nloss = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\natk = FGSM(model, eps=0)\natk1 = FGSM(model, eps=0.10)\natk2 = FGSM(model, eps=0.15)\natk3 = PGD(model, eps=0.10)\natk4 = PGD(model, eps=0.15)\natk5 = CW(model, c=0.10)\natk6 = CW(model, c=0.15)\n\nnum_epochs = 5\n\nfor epoch in range(num_epochs):\n\n    total_batch = len(mnist_train) // batch_size\n    \n    for i, (batch_images, batch_labels) in enumerate(train_loader):\n        # X = atk(batch_images, batch_labels).cuda()\n        Y = batch_labels.cuda()\n\n        pre = model(batch_images.cuda())\n        cost = loss(pre, Y)\n\n        optimizer.zero_grad()\n        cost.backward()\n        optimizer.step()\n\n        if (i+1) % 100 == 0:\n            print('Epoch [%d/%d], lter [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, i+1, total_batch, cost.item()))\n\nmodel.eval()\n\ncorrect = 0\ntotal = 0\n\nfor images, labels in test_loader:\n    \n    images = images.cuda()\n    outputs = model(images)\n    \n    _, predicted = torch.max(outputs.data, 1)\n    \n    total += labels.size(0)\n    correct += (predicted == labels.cuda()).sum()\n    \nprint('Standard accuracy: %.2f %%' % (100 * float(correct) / total))\n\n\"\"\"model.eval()\n\ncorrect = 0\ntotal = 0\n\nfor images, labels in test_loader:\n    \n    images = atk(images, labels).cuda()\n    outputs = model(images)\n    \n    _, predicted = torch.max(outputs.data, 1)\n    \n    total += labels.size(0)\n    correct += (predicted == labels.cuda()).sum()\n    \nprint('Robust accuracy: %.2f %%' % (100 * float(correct) / total))\"\"\"\n\nFreq_Scores = []\nAvg = [0]*10\nCount = [0]*10\n\nfor images, labels in test_loader:   \n\n    for m in range(28):\n        \n        img1 = images.cpu().numpy()\n        labels1 = labels.cpu()\n        \n        dct1 = dct(img1)\n        dct2 = dct1.copy()\n        mask = np.ma.masked_inside(np.abs(dct2),m,m+1).mask\n        dct2[mask] = np.random.randint(low=-10, high=10)\n        img2 = idct(dct2)\n\n        img1 = torch.tensor(img1.reshape(-1,1,28,28)).cuda()\n        img2 = torch.tensor(img2.reshape(-1,1,28,28)).cuda()\n        out1 = model(img1)\n        out2 = model(img2)\n\n        Classes = torch.max(out1.data,1)[1].cpu()\n        Diff = torch.sum(torch.abs(out1.data-out2.data),1).cpu()\n\n        for i,val in enumerate(Classes):\n            Avg[val] = (Avg[val]*Count[val] + Diff[i])/(Count[val]+1)\n            Count[val]+=1 \n        \n        Freq_Scores.append(Avg.copy())\n\nFreq_Scores = torch.tensor(Freq_Scores).view(-1,28,10)\nMean0 = torch.mean(Freq_Scores,0)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T15:10:31.468751Z","iopub.execute_input":"2021-10-23T15:10:31.469054Z","iopub.status.idle":"2021-10-23T15:13:05.314902Z","shell.execute_reply.started":"2021-10-23T15:10:31.469021Z","shell.execute_reply":"2021-10-23T15:13:05.313841Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model = models.resnet18()\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nmodel.fc = torch.nn.Linear(512, 10)\nmodel = model.cuda()\n\nloss = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# atk = PGD(model, eps=0.01)\natk1 = FGSM(model, eps=0.10)\natk2 = FGSM(model, eps=0.15)\natk3 = FGSM(model, eps=0.20)\natk4 = PGD(model, eps=0.10)\natk5 = PGD(model, eps=0.15)\natk6 = PGD(model, eps=0.20)\n\nnum_epochs = 5\n\nfor epoch in range(num_epochs):\n\n    total_batch = len(mnist_train) // batch_size\n    \n    for i, (batch_images, batch_labels) in enumerate(train_loader):\n        X = atk1(batch_images, batch_labels).cuda()\n        Y = batch_labels.cuda()\n\n        pre = model(X)\n        cost = loss(pre, Y)\n\n        optimizer.zero_grad()\n        cost.backward()\n        optimizer.step()\n\n        if (i+1) % 100 == 0:\n            print('Epoch [%d/%d], lter [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, i+1, total_batch, cost.item()))\n\nmodel.eval()\n\ncorrect = 0\ntotal = 0\n\nfor images, labels in test_loader:\n    \n    images = images.cuda()\n    outputs = model(images)\n    \n    _, predicted = torch.max(outputs.data, 1)\n    \n    total += labels.size(0)\n    correct += (predicted == labels.cuda()).sum()\n    \nprint('Standard accuracy: %.2f %%' % (100 * float(correct) / total))\n\nmodel.eval()\n\ncorrect = 0\ntotal = 0\n\nfor images, labels in test_loader:\n    \n    images = atk1(images, labels).cuda()\n    outputs = model(images)\n    \n    _, predicted = torch.max(outputs.data, 1)\n    \n    total += labels.size(0)\n    correct += (predicted == labels.cuda()).sum()\n    \nprint('Robust accuracy: %.2f %%' % (100 * float(correct) / total))\n\nFreq_Scores = []\nAvg = [0]*10\nCount = [0]*10\n\nfor images, labels in test_loader:   \n\n    for m in range(28):\n        \n        img1 = images.cpu().numpy()\n        labels1 = labels.cpu()\n        \n        dct1 = dct(img1)\n        dct2 = dct1.copy()\n        mask = np.ma.masked_inside(np.abs(dct2),m,m+1).mask\n        dct2[mask] = np.random.randint(low=-10, high=10)\n        img2 = idct(dct2)\n\n        img1 = torch.tensor(img1.reshape(-1,1,28,28)).cuda()\n        img2 = torch.tensor(img2.reshape(-1,1,28,28)).cuda()\n        out1 = model(img1)\n        out2 = model(img2)\n\n        Classes = torch.max(out1.data,1)[1].cpu()\n        Diff = torch.sum(torch.abs(out1.data-out2.data),1).cpu()\n\n        for i,val in enumerate(Classes):\n            Avg[val] = (Avg[val]*Count[val] + Diff[i])/(Count[val]+1)\n            Count[val]+=1 \n        \n        Freq_Scores.append(Avg.copy())\n\nFreq_Scores = torch.tensor(Freq_Scores).view(-1,28,10)\nMean1 = torch.mean(Freq_Scores,0)\n\nFreq1 = np.zeros((28,28))\n\nfor images, labels in test_loader:\n    \n    attacked = atk1(images, labels).cuda()\n    dummy = np.zeros((28,28))\n    for img, atc in zip(images,attacked):\n        true_tr = dct(img.cpu().numpy()).reshape(28,28)\n        attacked_tr = dct(atc.cpu().numpy()).reshape(28,28)\n        \n        for i in range(28):\n            for j in range(28):\n                if true_tr[i][j]==0:\n                    dummy[i][j]=0\n                else:\n                    dummy[i][j]=np.abs((attacked_tr[i][j]-true_tr[i][j])/true_tr[i][j])\n    Freq1+=dummy\n\nFreq1 = (Freq1-np.min(Freq1))/(np.max(Freq1)-np.min(Freq1))","metadata":{"execution":{"iopub.status.busy":"2021-10-23T09:17:36.227038Z","iopub.execute_input":"2021-10-23T09:17:36.227304Z","iopub.status.idle":"2021-10-23T09:21:21.768042Z","shell.execute_reply.started":"2021-10-23T09:17:36.227274Z","shell.execute_reply":"2021-10-23T09:21:21.767286Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true},"trusted":true},"execution_count":247,"outputs":[]},{"cell_type":"code","source":"model = models.resnet18()\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nmodel.fc = torch.nn.Linear(512, 10)\nmodel = model.cuda()\n\nloss = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# atk = PGD(model, eps=0.01)\natk1 = FGSM(model, eps=0.10)\natk2 = FGSM(model, eps=0.15)\natk3 = FGSM(model, eps=0.20)\natk4 = PGD(model, eps=0.10)\natk5 = PGD(model, eps=0.15)\natk6 = PGD(model, eps=0.20)\n\nnum_epochs = 5\n\nfor epoch in range(num_epochs):\n\n    total_batch = len(mnist_train) // batch_size\n    \n    for i, (batch_images, batch_labels) in enumerate(train_loader):\n        X = atk2(batch_images, batch_labels).cuda()\n        Y = batch_labels.cuda()\n\n        pre = model(X)\n        cost = loss(pre, Y)\n\n        optimizer.zero_grad()\n        cost.backward()\n        optimizer.step()\n\n        if (i+1) % 100 == 0:\n            print('Epoch [%d/%d], lter [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, i+1, total_batch, cost.item()))\n\nmodel.eval()\n\ncorrect = 0\ntotal = 0\n\nfor images, labels in test_loader:\n    \n    images = images.cuda()\n    outputs = model(images)\n    \n    _, predicted = torch.max(outputs.data, 1)\n    \n    total += labels.size(0)\n    correct += (predicted == labels.cuda()).sum()\n    \nprint('Standard accuracy: %.2f %%' % (100 * float(correct) / total))\n\nmodel.eval()\n\ncorrect = 0\ntotal = 0\n\nfor images, labels in test_loader:\n    \n    images = atk2(images, labels).cuda()\n    outputs = model(images)\n    \n    _, predicted = torch.max(outputs.data, 1)\n    \n    total += labels.size(0)\n    correct += (predicted == labels.cuda()).sum()\n    \nprint('Robust accuracy: %.2f %%' % (100 * float(correct) / total))\n\nFreq_Scores = []\nAvg = [0]*10\nCount = [0]*10\n\nfor images, labels in test_loader:   \n\n    for m in range(28):\n        \n        img1 = images.cpu().numpy()\n        labels1 = labels.cpu()\n        \n        dct1 = dct(img1)\n        dct2 = dct1.copy()\n        mask = np.ma.masked_inside(np.abs(dct2),m,m+1).mask\n        dct2[mask] = np.random.randint(low=-10, high=10)\n        img2 = idct(dct2)\n\n        img1 = torch.tensor(img1.reshape(-1,1,28,28)).cuda()\n        img2 = torch.tensor(img2.reshape(-1,1,28,28)).cuda()\n        out1 = model(img1)\n        out2 = model(img2)\n\n        Classes = torch.max(out1.data,1)[1].cpu()\n        Diff = torch.sum(torch.abs(out1.data-out2.data),1).cpu()\n\n        for i,val in enumerate(Classes):\n            Avg[val] = (Avg[val]*Count[val] + Diff[i])/(Count[val]+1)\n            Count[val]+=1 \n        \n        Freq_Scores.append(Avg.copy())\n\nFreq_Scores = torch.tensor(Freq_Scores).view(-1,28,10)\nMean2 = torch.mean(Freq_Scores,0)\n\nFreq2 = np.zeros((28,28))\n\nfor images, labels in test_loader:\n    \n    attacked = atk2(images, labels).cuda()\n    dummy = np.zeros((28,28))\n    for img, atc in zip(images,attacked):\n        true_tr = dct(img.cpu().numpy()).reshape(28,28)\n        attacked_tr = dct(atc.cpu().numpy()).reshape(28,28)\n        \n        for i in range(28):\n            for j in range(28):\n                if true_tr[i][j]==0:\n                    dummy[i][j]=0\n                else:\n                    dummy[i][j]=np.abs((attacked_tr[i][j]-true_tr[i][j])/true_tr[i][j])\n    Freq2+=dummy\n\nFreq2 = (Freq2-np.min(Freq2))/(np.max(Freq2)-np.min(Freq2))","metadata":{"execution":{"iopub.status.busy":"2021-10-23T09:21:21.769617Z","iopub.execute_input":"2021-10-23T09:21:21.769867Z","iopub.status.idle":"2021-10-23T09:25:08.411956Z","shell.execute_reply.started":"2021-10-23T09:21:21.769834Z","shell.execute_reply":"2021-10-23T09:25:08.411181Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true},"trusted":true},"execution_count":248,"outputs":[]},{"cell_type":"code","source":"model = models.resnet18()\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nmodel.fc = torch.nn.Linear(512, 10)\nmodel = model.cuda()\n\nloss = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# atk = PGD(model, eps=0.01)\natk1 = FGSM(model, eps=0.10)\natk2 = FGSM(model, eps=0.15)\natk3 = FGSM(model, eps=0.20)\natk4 = PGD(model, eps=0.10)\natk5 = PGD(model, eps=0.15)\natk6 = PGD(model, eps=0.20)\n\nnum_epochs = 3\n\nfor epoch in range(num_epochs):\n\n    total_batch = len(mnist_train) // batch_size\n    \n    for i, (batch_images, batch_labels) in enumerate(train_loader):\n        X = atk3(batch_images, batch_labels).cuda()\n        Y = batch_labels.cuda()\n\n        pre = model(X)\n        cost = loss(pre, Y)\n\n        optimizer.zero_grad()\n        cost.backward()\n        optimizer.step()\n\n        if (i+1) % 100 == 0:\n            print('Epoch [%d/%d], lter [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, i+1, total_batch, cost.item()))\n\nmodel.eval()\n\ncorrect = 0\ntotal = 0\n\nfor images, labels in test_loader:\n    \n    images = images.cuda()\n    outputs = model(images)\n    \n    _, predicted = torch.max(outputs.data, 1)\n    \n    total += labels.size(0)\n    correct += (predicted == labels.cuda()).sum()\n    \nprint('Standard accuracy: %.2f %%' % (100 * float(correct) / total))","metadata":{"execution":{"iopub.status.busy":"2021-10-23T13:21:57.484138Z","iopub.execute_input":"2021-10-23T13:21:57.484475Z","iopub.status.idle":"2021-10-23T13:49:12.491933Z","shell.execute_reply.started":"2021-10-23T13:21:57.484434Z","shell.execute_reply":"2021-10-23T13:49:12.490936Z"},"jupyter":{"outputs_hidden":true,"source_hidden":true},"collapsed":true,"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"Freq_Scores = []\nAvg = [0]*10\nCount = [0]*10\n\nfor images, labels in test_loader:   \n\n    for m in range(28):\n        \n        img1 = images.cpu().numpy()\n        labels1 = labels.cpu()\n        \n        dct1 = dct(img1)\n        dct2 = dct1.copy()\n        mask = np.ma.masked_inside(np.abs(dct2),m,m+1).mask\n        dct2[mask] = np.random.randint(low=-10, high=10)\n        img2 = idct(dct2)\n\n        img1 = torch.tensor(img1.reshape(-1,1,28,28)).cuda()\n        img2 = torch.tensor(img2.reshape(-1,1,28,28)).cuda()\n        out1 = model(img1)\n        out2 = model(img2)\n\n        Classes = torch.max(out1.data,1)[1].cpu()\n        Diff = torch.sum(torch.abs(out1.data-out2.data),1).cpu()\n\n        for i,val in enumerate(Classes):\n            Avg[val] = (Avg[val]*Count[val] + Diff[i])/(Count[val]+1)\n            Count[val]+=1 \n        \n        Freq_Scores.append(Avg.copy())\n\nFreq_Scores = torch.tensor(Freq_Scores).view(-1,28,10)\nMean3 = torch.mean(Freq_Scores,0)\n\nFreq3 = np.zeros((28,28))\n\nfor images, labels in test_loader:\n    \n    attacked = atk3(images, labels).cuda()\n    dummy = np.zeros((28,28))\n    for img, atc in zip(images,attacked):\n        true_tr = dct(img.cpu().numpy()).reshape(28,28)\n        attacked_tr = dct(atc.cpu().numpy()).reshape(28,28)\n        \n        for i in range(28):\n            for j in range(28):\n                if true_tr[i][j]==0:\n                    dummy[i][j]=0\n                else:\n                    dummy[i][j]=np.abs((attacked_tr[i][j]-true_tr[i][j])/true_tr[i][j])\n    Freq3+=dummy\n\nFreq3 = (Freq3-np.min(Freq3))/(np.max(Freq3)-np.min(Freq3))","metadata":{"execution":{"iopub.status.busy":"2021-10-23T14:02:55.003890Z","iopub.execute_input":"2021-10-23T14:02:55.004167Z","iopub.status.idle":"2021-10-23T14:06:11.459587Z","shell.execute_reply.started":"2021-10-23T14:02:55.004136Z","shell.execute_reply":"2021-10-23T14:06:11.458620Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = models.resnet18()\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nmodel.fc = torch.nn.Linear(512, 10)\nmodel = model.cuda()\n\nloss = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# atk = PGD(model, eps=0.01)\natk1 = FGSM(model, eps=0.10)\natk2 = FGSM(model, eps=0.15)\natk3 = FGSM(model, eps=0.20)\natk4 = PGD(model, eps=0.10)\natk5 = PGD(model, eps=0.15)\natk6 = PGD(model, eps=0.20)\n\nnum_epochs = 2\n\nfor epoch in range(num_epochs):\n\n    total_batch = len(mnist_train) // batch_size\n    \n    for i, (batch_images, batch_labels) in enumerate(train_loader):\n        X = atk4(batch_images, batch_labels).cuda()\n        Y = batch_labels.cuda()\n\n        pre = model(X)\n        cost = loss(pre, Y)\n\n        optimizer.zero_grad()\n        cost.backward()\n        optimizer.step()\n\n        if (i+1) % 100 == 0:\n            print('Epoch [%d/%d], lter [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, i+1, total_batch, cost.item()))\n\nmodel.eval()\n\ncorrect = 0\ntotal = 0\n\nfor images, labels in test_loader:\n    \n    images = images.cuda()\n    outputs = model(images)\n    \n    _, predicted = torch.max(outputs.data, 1)\n    \n    total += labels.size(0)\n    correct += (predicted == labels.cuda()).sum()\n    \nprint('Standard accuracy: %.2f %%' % (100 * float(correct) / total))\n\nmodel.eval()\n\ncorrect = 0\ntotal = 0\n\nfor images, labels in test_loader:\n    \n    images = atk4(images, labels).cuda()\n    outputs = model(images)\n    \n    _, predicted = torch.max(outputs.data, 1)\n    \n    total += labels.size(0)\n    correct += (predicted == labels.cuda()).sum()\n    \nprint('Robust accuracy: %.2f %%' % (100 * float(correct) / total))\n\nFreq_Scores = []\nAvg = [0]*10\nCount = [0]*10\n\nfor images, labels in test_loader:   \n\n    for m in range(28):\n        \n        img1 = images.cpu().numpy()\n        labels1 = labels.cpu()\n        \n        dct1 = dct(img1)\n        dct2 = dct1.copy()\n        mask = np.ma.masked_inside(np.abs(dct2),m,m+1).mask\n        dct2[mask] = np.random.randint(low=-10, high=10)\n        img2 = idct(dct2)\n\n        img1 = torch.tensor(img1.reshape(-1,1,28,28)).cuda()\n        img2 = torch.tensor(img2.reshape(-1,1,28,28)).cuda()\n        out1 = model(img1)\n        out2 = model(img2)\n\n        Classes = torch.max(out1.data,1)[1].cpu()\n        Diff = torch.sum(torch.abs(out1.data-out2.data),1).cpu()\n\n        for i,val in enumerate(Classes):\n            Avg[val] = (Avg[val]*Count[val] + Diff[i])/(Count[val]+1)\n            Count[val]+=1 \n        \n        Freq_Scores.append(Avg.copy())\n\nFreq_Scores = torch.tensor(Freq_Scores).view(-1,28,10)\nMean4 = torch.mean(Freq_Scores,0)\n\nFreq4 = np.zeros((28,28))\n\nfor images, labels in test_loader:\n    \n    attacked = atk4(images, labels).cuda()\n    dummy = np.zeros((28,28))\n    for img, atc in zip(images,attacked):\n        true_tr = dct(img.cpu().numpy()).reshape(28,28)\n        attacked_tr = dct(atc.cpu().numpy()).reshape(28,28)\n        \n        for i in range(28):\n            for j in range(28):\n                if true_tr[i][j]==0:\n                    dummy[i][j]=0\n                else:\n                    dummy[i][j]=np.abs((attacked_tr[i][j]-true_tr[i][j])/true_tr[i][j])\n    Freq4+=dummy\n\nFreq4 = (Freq4-np.min(Freq4))/(np.max(Freq4)-np.min(Freq4))","metadata":{"execution":{"iopub.status.busy":"2021-10-23T15:15:56.228462Z","iopub.execute_input":"2021-10-23T15:15:56.228767Z","iopub.status.idle":"2021-10-23T15:35:51.285571Z","shell.execute_reply.started":"2021-10-23T15:15:56.228734Z","shell.execute_reply":"2021-10-23T15:35:51.284463Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model = models.resnet18()\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nmodel.fc = torch.nn.Linear(512, 10)\nmodel = model.cuda()\n\nloss = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# atk = PGD(model, eps=0.01)\natk1 = FGSM(model, eps=0.10)\natk2 = FGSM(model, eps=0.15)\natk3 = FGSM(model, eps=0.20)\natk4 = PGD(model, eps=0.10)\natk5 = PGD(model, eps=0.15)\natk6 = PGD(model, eps=0.20)\n\nnum_epochs = 2\n\nfor epoch in range(num_epochs):\n\n    total_batch = len(mnist_train) // batch_size\n    \n    for i, (batch_images, batch_labels) in enumerate(train_loader):\n        X = atk5(batch_images, batch_labels).cuda()\n        Y = batch_labels.cuda()\n\n        pre = model(X)\n        cost = loss(pre, Y)\n\n        optimizer.zero_grad()\n        cost.backward()\n        optimizer.step()\n\n        if (i+1) % 100 == 0:\n            print('Epoch [%d/%d], lter [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, i+1, total_batch, cost.item()))\n\nmodel.eval()\n\ncorrect = 0\ntotal = 0\n\nfor images, labels in test_loader:\n    \n    images = images.cuda()\n    outputs = model(images)\n    \n    _, predicted = torch.max(outputs.data, 1)\n    \n    total += labels.size(0)\n    correct += (predicted == labels.cuda()).sum()\n    \nprint('Standard accuracy: %.2f %%' % (100 * float(correct) / total))\n\nmodel.eval()\n\ncorrect = 0\ntotal = 0\n\nfor images, labels in test_loader:\n    \n    images = atk5(images, labels).cuda()\n    outputs = model(images)\n    \n    _, predicted = torch.max(outputs.data, 1)\n    \n    total += labels.size(0)\n    correct += (predicted == labels.cuda()).sum()\n    \nprint('Robust accuracy: %.2f %%' % (100 * float(correct) / total))\n\nFreq_Scores = []\nAvg = [0]*10\nCount = [0]*10\n\nfor images, labels in test_loader:   \n\n    for m in range(28):\n        \n        img1 = images.cpu().numpy()\n        labels1 = labels.cpu()\n        \n        dct1 = dct(img1)\n        dct2 = dct1.copy()\n        mask = np.ma.masked_inside(np.abs(dct2),m,m+1).mask\n        dct2[mask] = np.random.randint(low=-10, high=10)\n        img2 = idct(dct2)\n\n        img1 = torch.tensor(img1.reshape(-1,1,28,28)).cuda()\n        img2 = torch.tensor(img2.reshape(-1,1,28,28)).cuda()\n        out1 = model(img1)\n        out2 = model(img2)\n\n        Classes = torch.max(out1.data,1)[1].cpu()\n        Diff = torch.sum(torch.abs(out1.data-out2.data),1).cpu()\n\n        for i,val in enumerate(Classes):\n            Avg[val] = (Avg[val]*Count[val] + Diff[i])/(Count[val]+1)\n            Count[val]+=1 \n        \n        Freq_Scores.append(Avg.copy())\n\nFreq_Scores = torch.tensor(Freq_Scores).view(-1,28,10)\nMean5 = torch.mean(Freq_Scores,0)\n\nFreq5 = np.zeros((28,28))\n\nfor images, labels in test_loader:\n    \n    attacked = atk5(images, labels).cuda()\n    dummy = np.zeros((28,28))\n    for img, atc in zip(images,attacked):\n        true_tr = dct(img.cpu().numpy()).reshape(28,28)\n        attacked_tr = dct(atc.cpu().numpy()).reshape(28,28)\n        \n        for i in range(28):\n            for j in range(28):\n                if true_tr[i][j]==0:\n                    dummy[i][j]=0\n                else:\n                    dummy[i][j]=np.abs((attacked_tr[i][j]-true_tr[i][j])/true_tr[i][j])\n    Freq5+=dummy\n\nFreq5 = (Freq5-np.min(Freq5))/(np.max(Freq5)-np.min(Freq5))","metadata":{"execution":{"iopub.status.busy":"2021-10-23T14:48:19.827476Z","iopub.execute_input":"2021-10-23T14:48:19.828529Z","iopub.status.idle":"2021-10-23T15:08:13.577378Z","shell.execute_reply.started":"2021-10-23T14:48:19.828486Z","shell.execute_reply":"2021-10-23T15:08:13.576265Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model = models.resnet18()\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nmodel.fc = torch.nn.Linear(512, 10)\nmodel = model.cuda()\n\nloss = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# atk = PGD(model, eps=0.01)\natk1 = FGSM(model, eps=0.10)\natk2 = FGSM(model, eps=0.15)\natk3 = FGSM(model, eps=0.20)\natk4 = PGD(model, eps=0.10)\natk5 = PGD(model, c=0.15)\natk6 = PGD(model, eps=0.20)\n\nnum_epochs = 3\n\nfor epoch in range(num_epochs):\n\n    total_batch = len(mnist_train) // batch_size\n    \n    for i, (batch_images, batch_labels) in enumerate(train_loader):\n        X = atk6(batch_images, batch_labels).cuda()\n        Y = batch_labels.cuda()\n\n        pre = model(X)\n        cost = loss(pre, Y)\n\n        optimizer.zero_grad()\n        cost.backward()\n        optimizer.step()\n\n        if (i+1) % 100 == 0:\n            print('Epoch [%d/%d], lter [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, i+1, total_batch, cost.item()))\n\nmodel.eval()\n\ncorrect = 0\ntotal = 0\n\nfor images, labels in test_loader:\n    \n    images = images.cuda()\n    outputs = model(images)\n    \n    _, predicted = torch.max(outputs.data, 1)\n    \n    total += labels.size(0)\n    correct += (predicted == labels.cuda()).sum()\n    \nprint('Standard accuracy: %.2f %%' % (100 * float(correct) / total))\n\nmodel.eval()\n\ncorrect = 0\ntotal = 0\n\nfor images, labels in test_loader:\n    \n    images = atk6(images, labels).cuda()\n    outputs = model(images)\n    \n    _, predicted = torch.max(outputs.data, 1)\n    \n    total += labels.size(0)\n    correct += (predicted == labels.cuda()).sum()\n    \nprint('Robust accuracy: %.2f %%' % (100 * float(correct) / total))\n\nFreq_Scores = []\nAvg = [0]*10\nCount = [0]*10\n\nfor images, labels in test_loader:   \n\n    for m in range(28):\n        \n        img1 = images.cpu().numpy()\n        labels1 = labels.cpu()\n        \n        dct1 = dct(img1)\n        dct2 = dct1.copy()\n        mask = np.ma.masked_inside(np.abs(dct2),m,m+1).mask\n        dct2[mask] = np.random.randint(low=-10, high=10)\n        img2 = idct(dct2)\n\n        img1 = torch.tensor(img1.reshape(-1,1,28,28)).cuda()\n        img2 = torch.tensor(img2.reshape(-1,1,28,28)).cuda()\n        out1 = model(img1)\n        out2 = model(img2)\n\n        Classes = torch.max(out1.data,1)[1].cpu()\n        Diff = torch.sum(torch.abs(out1.data-out2.data),1).cpu()\n\n        for i,val in enumerate(Classes):\n            Avg[val] = (Avg[val]*Count[val] + Diff[i])/(Count[val]+1)\n            Count[val]+=1 \n        \n        Freq_Scores.append(Avg.copy())\n\nFreq_Scores = torch.tensor(Freq_Scores).view(-1,28,10)\nMean6 = torch.mean(Freq_Scores,0)\n\nFreq6 = np.zeros((28,28))\n\nfor images, labels in test_loader:\n    \n    attacked = atk6(images, labels).cuda()\n    dummy = np.zeros((28,28))\n    for img, atc in zip(images,attacked):\n        true_tr = dct(img.cpu().numpy()).reshape(28,28)\n        attacked_tr = dct(atc.cpu().numpy()).reshape(28,28)\n        \n        for i in range(28):\n            for j in range(28):\n                if true_tr[i][j]==0:\n                    dummy[i][j]=0\n                else:\n                    dummy[i][j]=np.abs((attacked_tr[i][j]-true_tr[i][j])/true_tr[i][j])\n    Freq6+=dummy\n\nFreq6 = (Freq6-np.min(Freq6))/(np.max(Freq6)-np.min(Freq6))","metadata":{"execution":{"iopub.status.busy":"2021-10-23T14:13:48.323740Z","iopub.execute_input":"2021-10-23T14:13:48.324026Z","iopub.status.idle":"2021-10-23T14:41:28.649211Z","shell.execute_reply.started":"2021-10-23T14:13:48.323996Z","shell.execute_reply":"2021-10-23T14:41:28.648151Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(2, 5, figsize=(20,7))\n#axs[0,0].plot(Mean0[:,0], label='Natural')\n#axs[0,1].plot(Mean0[:,1], label='Natural')\n#axs[0,2].plot(Mean0[:,2], label='Natural')\n#axs[0,3].plot(Mean0[:,3], label='Natural')\n#axs[0,4].plot(Mean0[:,4], label='Natural')\n#axs[1,0].plot(Mean0[:,5], label='Natural')\n#axs[1,1].plot(Mean0[:,6], label='Natural')\n#axs[1,2].plot(Mean0[:,7], label='Natural')\n#axs[1,3].plot(Mean0[:,8], label='Natural')\n#axs[1,4].plot(Mean0[:,9], label='Natural')\n#axs[0,0].plot(Mean4[:,0], label='PGD eps=0.10')\n#axs[0,0].plot(Mean5[:,0], label='PGD eps=0.15')\naxs[0,0].plot(Mean6[:,0], label='PGD eps=0.20')\naxs[0,0].legend()\n#axs[0,1].plot(Mean4[:,1], label='PGD eps=0.10')\n#axs[0,1].plot(Mean5[:,1], label='PGD eps=0.15')\naxs[0,1].plot(Mean6[:,1], label='PGD eps=0.20')\naxs[0,1].legend()\n#axs[0,2].plot(Mean4[:,2], label='PGD eps=0.10')\n#axs[0,2].plot(Mean5[:,2], label='PGD eps=0.15')\naxs[0,2].plot(Mean6[:,2], label='PGD eps=0.20')\naxs[0,2].legend()\n#axs[0,3].plot(Mean4[:,3], label='PGD eps=0.10')\n#axs[0,3].plot(Mean5[:,3], label='PGD eps=0.15')\naxs[0,3].plot(Mean6[:,3], label='PGD eps=0.20')\naxs[0,3].legend()\n#axs[0,4].plot(Mean4[:,4], label='PGD eps=0.10')\n#axs[0,4].plot(Mean5[:,4], label='PGD eps=0.15')\naxs[0,4].plot(Mean6[:,4], label='PGD eps=0.20')\naxs[0,4].legend()\n#axs[1,0].plot(Mean4[:,5], label='PGD eps=0.10')\n#axs[1,0].plot(Mean5[:,5], label='PGD eps=0.15')\naxs[1,0].plot(Mean6[:,5], label='PGD eps=0.20')\naxs[1,0].legend()\n#axs[1,1].plot(Mean4[:,6], label='PGD eps=0.10')\n#axs[1,1].plot(Mean5[:,6], label='PGD eps=0.15')\naxs[1,1].plot(Mean6[:,6], label='PGD eps=0.20')\naxs[1,1].legend()\n#axs[1,2].plot(Mean4[:,7], label='PGD eps=0.10')\n#axs[1,2].plot(Mean5[:,7], label='PGD eps=0.15')\naxs[1,2].plot(Mean6[:,7], label='PGD eps=0.20')\naxs[1,2].legend()\n#axs[1,3].plot(Mean4[:,8], label='PGD eps=0.10')\n#axs[1,3].plot(Mean5[:,8], label='PGD eps=0.15')\naxs[1,3].plot(Mean6[:,8], label='PGD eps=0.20')\naxs[1,3].legend()\n#axs[1,4].plot(Mean4[:,9], label='PGD eps=0.10')\n#axs[1,4].plot(Mean5[:,9], label='PGD eps=0.15')\naxs[1,4].plot(Mean6[:,9], label='PGD eps=0.20')\naxs[1,4].legend()\naxs[0,0].set_title('0')\naxs[0,1].set_title('1')\naxs[0,2].set_title('2')\naxs[0,3].set_title('3')\naxs[0,4].set_title('4')\naxs[1,0].set_title('5')\naxs[1,1].set_title('6')\naxs[1,2].set_title('7')\naxs[1,3].set_title('8')\naxs[1,4].set_title('9')\nplt.savefig('PGD_0.20_FAS_Scores.png')","metadata":{"execution":{"iopub.status.busy":"2021-10-23T15:50:16.779728Z","iopub.execute_input":"2021-10-23T15:50:16.780019Z","iopub.status.idle":"2021-10-23T15:50:19.727988Z","shell.execute_reply.started":"2021-10-23T15:50:16.779973Z","shell.execute_reply":"2021-10-23T15:50:19.726939Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 3, figsize=(15,5))\nm1 = axs[0].imshow(Freq4, label='PGD eps=0.10')\nm2 = axs[1].imshow(Freq5, label='PGD eps=0.15')\nm3 = axs[2].imshow(Freq6, label='PGD eps=0.20')\n#m4 = axs[1,1].imshow(Freq2, label='PGD eps=0.15')\n\naxs[0].set_title(\"PGD eps=0.10\")\naxs[1].set_title(\"PGD eps=0.15\")\naxs[2].set_title(\"PGD eps=0.20\")\ndivider = make_axes_locatable(axs[0])\ncax = divider.append_axes('right', size='5%', pad=0.05)\nfig.colorbar(m1, cax=cax, orientation='vertical')\ndivider = make_axes_locatable(axs[1])\ncax = divider.append_axes('right', size='5%', pad=0.05)\nfig.colorbar(m2, cax=cax, orientation='vertical')\ndivider = make_axes_locatable(axs[2])\ncax = divider.append_axes('right', size='5%', pad=0.05)\nfig.colorbar(m3, cax=cax, orientation='vertical')\n\nplt.savefig(\"PGD_RCT_Maps.png\")","metadata":{"execution":{"iopub.status.busy":"2021-10-23T15:37:36.670807Z","iopub.execute_input":"2021-10-23T15:37:36.671138Z","iopub.status.idle":"2021-10-23T15:37:37.647349Z","shell.execute_reply.started":"2021-10-23T15:37:36.671105Z","shell.execute_reply":"2021-10-23T15:37:37.646360Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}